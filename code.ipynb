{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fc040f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\WELCOME\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import model building libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f854bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff1f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.configure image data generator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d927bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Apply image data generator functionality to train and test images\n",
    "x_train=train_datagen.flow_from_directory(r'C:\\Users\\WELCOME\\OneDrive\\Documents\\AI_ML\\genLogoOutput',target_size=(64,64),batch_size=16,class_mode=\"categorical\")\n",
    "x_test = test_datagen.flow_from_directory(r'C:\\Users\\WELCOME\\OneDrive\\Documents\\AI_ML\\output',target_size = (64,64),batch_size=16,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4a3fec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Adidas': 0, 'Amazon': 1, 'Android': 2, 'Apple': 3, 'Ariel': 4, 'BMW': 5, 'Bic': 6, 'Burger King': 7, 'Cadbury': 8, 'Chevrolet': 9, 'Chrome': 10, 'Coca Cola': 11, 'Cowbell': 12, 'Dominos': 13, 'Fila': 14, 'Gillette': 15, 'Google': 16, 'Goya oil': 17, 'Guinness': 18, 'Heinz': 19, 'Honda': 20, 'Hp': 21, 'Huawei': 22, 'Instagram': 23, 'Kfc': 24, 'Krisspy Kreme': 25, 'Lays': 26, 'Levis': 27, 'Lg': 28, 'Lipton': 29, 'Mars': 30, 'Marvel': 31, 'McDonald': 32, 'Mercedes Benz': 33, 'Microsoft': 34, 'MnM': 35, 'Mtn': 36, 'Mtn dew': 37, 'NASA': 38, 'Nescafe': 39, 'Nestle': 40, 'Nestle milo': 41, 'Netflix': 42, 'Nike': 43, 'Nutella': 44, 'Oral b': 45, 'Oreo': 46, 'Pay pal': 47, 'Peak milk': 48, 'Pepsi': 49, 'PlayStation': 50, 'Pringles': 51, 'Puma': 52, 'Reebok': 53, 'Rolex': 54, 'Samsung': 55, 'Sprite': 56, 'Starbucks': 57, 'Tesla': 58, 'Tiktok': 59, 'Twitter': 60, 'YouTube': 61, 'Zara': 62}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "642e1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.initializing the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "41b0ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.add convolution layer(no.of filters,size of filter,input shape)\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99000c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add max pool layer(pool_size)\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d6691f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add flatten layer ---input of ann\n",
    "model.add(Flatten(input_shape=(64, 64, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc88ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hidden layer\n",
    "model.add(Dense(units=128, activation=\"relu\", input_shape=(64, 64, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d803a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add output layer\n",
    "model.add(Dense(units=63,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7dc8662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model (loss fucntion,accuracy,optimizer)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee217090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "35/35 [==============================] - 7s 153ms/step - loss: 4.4404 - accuracy: 0.0382 - val_loss: 3.8278 - val_accuracy: 0.1063\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 5s 135ms/step - loss: 3.7564 - accuracy: 0.0982 - val_loss: 3.3238 - val_accuracy: 0.1625\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 4s 127ms/step - loss: 3.2750 - accuracy: 0.2018 - val_loss: 2.6804 - val_accuracy: 0.3625\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 5s 129ms/step - loss: 2.6715 - accuracy: 0.3291 - val_loss: 1.9903 - val_accuracy: 0.4750\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 4s 126ms/step - loss: 2.0501 - accuracy: 0.4927 - val_loss: 1.4668 - val_accuracy: 0.6438\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 4s 124ms/step - loss: 1.5363 - accuracy: 0.5782 - val_loss: 0.9986 - val_accuracy: 0.7812\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 5s 140ms/step - loss: 1.2048 - accuracy: 0.6982 - val_loss: 0.8251 - val_accuracy: 0.7563\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 5s 148ms/step - loss: 0.9840 - accuracy: 0.7600 - val_loss: 0.5739 - val_accuracy: 0.8750\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 5s 135ms/step - loss: 0.7371 - accuracy: 0.8200 - val_loss: 0.4428 - val_accuracy: 0.9062\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 5s 135ms/step - loss: 0.6804 - accuracy: 0.8418 - val_loss: 0.2265 - val_accuracy: 0.9375\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 5s 133ms/step - loss: 0.4979 - accuracy: 0.8764 - val_loss: 0.2353 - val_accuracy: 0.9375\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 5s 140ms/step - loss: 0.3785 - accuracy: 0.9036 - val_loss: 0.2055 - val_accuracy: 0.9563\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 5s 133ms/step - loss: 0.3673 - accuracy: 0.9109 - val_loss: 0.1786 - val_accuracy: 0.9625\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 5s 132ms/step - loss: 0.2678 - accuracy: 0.9200 - val_loss: 0.0899 - val_accuracy: 0.9750\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 5s 129ms/step - loss: 0.2846 - accuracy: 0.9473 - val_loss: 0.1122 - val_accuracy: 0.9750\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 5s 129ms/step - loss: 0.2249 - accuracy: 0.9436 - val_loss: 0.1356 - val_accuracy: 0.9563\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 4s 126ms/step - loss: 0.2980 - accuracy: 0.9309 - val_loss: 0.1918 - val_accuracy: 0.9375\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - 5s 129ms/step - loss: 0.1640 - accuracy: 0.9582 - val_loss: 0.0933 - val_accuracy: 0.9750\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 5s 154ms/step - loss: 0.1352 - accuracy: 0.9727 - val_loss: 0.0609 - val_accuracy: 0.9875\n",
      "Epoch 20/20\n",
      "35/35 [==============================] - 5s 136ms/step - loss: 0.1183 - accuracy: 0.9691 - val_loss: 0.0457 - val_accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23aebd9fc90>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model (x_train,steps_per epoch,epochs,validation_data,validation_steps)\n",
    "model.fit(x_train,epochs=20,validation_data=x_test,validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "274fbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import load_model from keras.models\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "model_save_path = 'logo_detection_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc24a13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WELCOME\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea1466e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ad523c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Model Summary:\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 31, 31, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 30752)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               3936384   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 63)                8127      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3945407 (15.05 MB)\n",
      "Trainable params: 3945407 (15.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoaded Model Summary:\")\n",
    "print(loaded_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f80dcaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 26ms/step - loss: 0.0493 - accuracy: 0.9891\n",
      "Test Accuracy: 98.91%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_loss, test_accuracy = loaded_model.evaluate(x_test)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0cf445b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 64, 64\n",
    "input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1364b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logo(image_path):\n",
    "    img = load_img(image_path, target_size=(img_width, img_height))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x / 255.0  # Normalize the image\n",
    "    preds = model.predict(x)\n",
    "    classes = x_train.class_indices\n",
    "    predicted_class = list(classes.keys())[list(classes.values()).index(np.argmax(preds))]\n",
    "    \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a970f285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 195ms/step\n",
      "The predicted logo is: Apple\n"
     ]
    }
   ],
   "source": [
    "new_image_path = r'C:\\Users\\WELCOME\\OneDrive\\Documents\\AI_ML\\genLogoOutput\\Apple\\000001.jpg'\n",
    "predicted_logo = predict_logo(new_image_path)\n",
    "print(f'The predicted logo is: {predicted_logo}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
